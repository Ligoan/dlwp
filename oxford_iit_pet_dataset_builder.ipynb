{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding=utf-8\n",
    "# Copyright 2024 The TensorFlow Datasets Authors.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "\"\"\"Oxford-IIIT pet dataset.\"\"\"\n",
    "\n",
    "import os\n",
    "\n",
    "from tensorflow_datasets.core.utils.lazy_imports_utils import tensorflow as tf\n",
    "import tensorflow_datasets.public_api as tfds\n",
    "\n",
    "_BASE_URL = \"http://www.robots.ox.ac.uk/~vgg/data/pets/data\"\n",
    "\n",
    "_LABEL_CLASSES = [\n",
    "    \"Abyssinian\",\n",
    "    \"american_bulldog\",\n",
    "    \"american_pit_bull_terrier\",\n",
    "    \"basset_hound\",\n",
    "    \"beagle\",\n",
    "    \"Bengal\",\n",
    "    \"Birman\",\n",
    "    \"Bombay\",\n",
    "    \"boxer\",\n",
    "    \"British_Shorthair\",\n",
    "    \"chihuahua\",\n",
    "    \"Egyptian_Mau\",\n",
    "    \"english_cocker_spaniel\",\n",
    "    \"english_setter\",\n",
    "    \"german_shorthaired\",\n",
    "    \"great_pyrenees\",\n",
    "    \"havanese\",\n",
    "    \"japanese_chin\",\n",
    "    \"keeshond\",\n",
    "    \"leonberger\",\n",
    "    \"Maine_Coon\",\n",
    "    \"miniature_pinscher\",\n",
    "    \"newfoundland\",\n",
    "    \"Persian\",\n",
    "    \"pomeranian\",\n",
    "    \"pug\",\n",
    "    \"Ragdoll\",\n",
    "    \"Russian_Blue\",\n",
    "    \"saint_bernard\",\n",
    "    \"samoyed\",\n",
    "    \"scottish_terrier\",\n",
    "    \"shiba_inu\",\n",
    "    \"Siamese\",\n",
    "    \"Sphynx\",\n",
    "    \"staffordshire_bull_terrier\",\n",
    "    \"wheaten_terrier\",\n",
    "    \"yorkshire_terrier\",\n",
    "]\n",
    "_SPECIES_CLASSES = [\"Cat\", \"Dog\"]\n",
    "\n",
    "\n",
    "class Builder(tfds.core.GeneratorBasedBuilder):\n",
    "  \"\"\"Oxford-IIIT pet dataset.\"\"\"\n",
    "\n",
    "  VERSION = tfds.core.Version(\"3.2.0\")\n",
    "\n",
    "  def _info(self):\n",
    "    return self.dataset_info_from_configs(\n",
    "        features=tfds.features.FeaturesDict({\n",
    "            \"image\": tfds.features.Image(),\n",
    "            \"label\": tfds.features.ClassLabel(names=_LABEL_CLASSES),\n",
    "            \"species\": tfds.features.ClassLabel(names=_SPECIES_CLASSES),\n",
    "            \"file_name\": tfds.features.Text(),\n",
    "            \"segmentation_mask\": tfds.features.Image(\n",
    "                shape=(None, None, 1), use_colormap=True\n",
    "            ),\n",
    "        }),\n",
    "        supervised_keys=(\"image\", \"label\"),\n",
    "        homepage=\"http://www.robots.ox.ac.uk/~vgg/data/pets/\",\n",
    "    )\n",
    "\n",
    "  def _split_generators(self, dl_manager):\n",
    "    \"\"\"Returns splits.\"\"\"\n",
    "    # Download images and annotations that come in separate archives.\n",
    "    # Note, that the extension of archives is .tar.gz even though the actual\n",
    "    # archives format is uncompressed tar.\n",
    "    dl_paths = dl_manager.download_and_extract({\n",
    "        \"images\": _BASE_URL + \"/images.tar.gz\",\n",
    "        \"annotations\": _BASE_URL + \"/annotations.tar.gz\",\n",
    "    })\n",
    "\n",
    "    images_path_dir = os.path.join(dl_paths[\"images\"], \"images\")\n",
    "    annotations_path_dir = os.path.join(dl_paths[\"annotations\"], \"annotations\")\n",
    "\n",
    "    # Setup train and test splits\n",
    "    train_split = tfds.core.SplitGenerator(\n",
    "        name=\"train\",\n",
    "        gen_kwargs={\n",
    "            \"images_dir_path\": images_path_dir,\n",
    "            \"annotations_dir_path\": annotations_path_dir,\n",
    "            \"images_list_file\": os.path.join(\n",
    "                annotations_path_dir, \"trainval.txt\"\n",
    "            ),\n",
    "        },\n",
    "    )\n",
    "    test_split = tfds.core.SplitGenerator(\n",
    "        name=\"test\",\n",
    "        gen_kwargs={\n",
    "            \"images_dir_path\": images_path_dir,\n",
    "            \"annotations_dir_path\": annotations_path_dir,\n",
    "            \"images_list_file\": os.path.join(annotations_path_dir, \"test.txt\"),\n",
    "        },\n",
    "    )\n",
    "\n",
    "    return [train_split, test_split]\n",
    "\n",
    "  def _generate_examples(\n",
    "      self, images_dir_path, annotations_dir_path, images_list_file\n",
    "  ):\n",
    "    with tf.io.gfile.GFile(images_list_file, \"r\") as images_list:\n",
    "      for line in images_list:\n",
    "        image_name, label, species, _ = line.strip().split(\" \")\n",
    "\n",
    "        trimaps_dir_path = os.path.join(annotations_dir_path, \"trimaps\")\n",
    "\n",
    "        trimap_name = image_name + \".png\"\n",
    "        image_name += \".jpg\"\n",
    "        label = int(label) - 1\n",
    "        species = int(species) - 1\n",
    "\n",
    "        record = {\n",
    "            \"image\": os.path.join(images_dir_path, image_name),\n",
    "            \"label\": int(label),\n",
    "            \"species\": species,\n",
    "            \"file_name\": image_name,\n",
    "            \"segmentation_mask\": os.path.join(trimaps_dir_path, trimap_name),\n",
    "        }\n",
    "        yield image_name, record"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
